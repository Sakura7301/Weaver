"""
AIå¯¹è¯æ ¸å¿ƒé€»è¾‘
"""
import json
from openai import OpenAI
from memory.core import MemorySystem
from memory.tools import create_memory_tools
from config import API_KEY, BASE_URL, JUDGE_MODEL, ANSWER_MODEL, TIMEZONE
from time_utils import get_current_time_info
from web_search import web_search

class AIChat:
    """AIå¯¹è¯å¤„ç†å™¨"""
    
    def __init__(self, memory_system, searxng_url, max_fetch=2):
        """
        åˆå§‹åŒ–AIå¯¹è¯å¤„ç†å™¨
        
        Args:
            memory_system: è®°å¿†ç³»ç»Ÿå®ä¾‹
            searxng_url: SearXNGæœåŠ¡å™¨åœ°å€
            max_fetch: æœ€å¤§çˆ¬å–ç½‘é¡µæ•°é‡
        """
        self.memory = memory_system
        self.searxng_url = searxng_url
        self.max_fetch = max_fetch
        self.client = OpenAI(api_key=API_KEY, base_url=BASE_URL)
        self.conversation_history = []
        
    def _build_system_prompt(self, time_text, long_term_memory):
        """æ„å»ºç³»ç»Ÿæç¤º"""
        return f"""ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œæ‹¥æœ‰è®°å¿†å’Œè”ç½‘èƒ½åŠ›ã€‚\n{time_text}\nã€é•¿æœŸè®°å¿†ã€‘\n{long_term_memory}\nã€å·¥ä½œæµç¨‹ã€‘\n1. å¦‚æœç”¨æˆ·é—®å½“å‰æ—¥æœŸ/æ—¶é—´ï¼Œç›´æ¥ç”¨ä¸Šè¿°ä¿¡æ¯å›ç­”ï¼Œæ— éœ€æœç´¢\n2. å¦‚æœç”¨æˆ·è¯¢é—®å†å²ä¿¡æ¯ã€åå¥½ã€è¿‡å¾€å¯¹è¯ï¼Œè°ƒç”¨ memory_search æœç´¢è®°å¿†\n3. å¦‚æœç”¨æˆ·æä¾›é‡è¦ä¿¡æ¯ï¼ˆä¸ªäººä¿¡æ¯ã€åå¥½ã€å†³ç­–ï¼‰ï¼Œè°ƒç”¨ memory_save ä¿å­˜\n4. å¦‚æœéœ€è¦å®æ—¶ä¿¡æ¯ï¼ˆæ–°é—»ã€ä»·æ ¼ã€å¤©æ°”ï¼‰ï¼Œè°ƒç”¨ web_search\n5. å¦‚æœæ˜¯é€šç”¨çŸ¥è¯†é—®é¢˜ï¼Œç›´æ¥å›ç­”\nã€é‡è¦ã€‘ä¿æŒä¸Šä¸‹æ–‡è¿è´¯æ€§ã€‚å›ç­”æ—¶è¦å¼•ç”¨æ¥æºã€‚"""
    
    def _extract_important_info(self, question, answer):
        """è‡ªåŠ¨æå–é‡è¦ä¿¡æ¯åˆ°é•¿æœŸè®°å¿†"""
        try:
            extract_prompt = f"""åˆ†æå¯¹è¯ï¼Œæå–å€¼å¾—é•¿æœŸè®°å¿†çš„é‡è¦ä¿¡æ¯ã€‚\nã€ç”¨æˆ·é—®é¢˜ã€‘\n{question}\nã€AIå›ç­”ã€‘\n{answer}\n**åˆ¤æ–­è§„åˆ™**ï¼š\néœ€è¦è®°å¿†çš„ä¿¡æ¯ç±»å‹ï¼š\n1. ç”¨æˆ·è‡ªæˆ‘ä»‹ç»ï¼ˆå§“åã€èº«ä»½ã€èŒä¸šã€è§’è‰²è®¾å®šï¼‰\n2. ç”¨æˆ·åå¥½ï¼ˆå–œå¥½ã€åŒæ¶ã€ä¹ æƒ¯ã€å…´è¶£çˆ±å¥½ï¼‰\n3. é‡è¦å…³ç³»ï¼ˆå¸ˆå¾’å…³ç³»ã€å®¶äººæœ‹å‹ã€å® ç‰©è§’è‰²ç­‰ï¼‰\n4. å…³é”®äº‹å®ï¼ˆå†³ç­–ã€è®¡åˆ’ã€é‡è¦ä¿¡æ¯ï¼‰\næ— éœ€è®°å¿†çš„ä¿¡æ¯ç±»å‹ï¼š\n- æ™®é€šé—®å€™ã€é—²èŠ\n- ä¸€æ¬¡æ€§é—®é¢˜\n- ä¸´æ—¶æŒ‡ä»¤\n**è¾“å‡ºæ ¼å¼**ï¼š\nå¦‚æœæœ‰é‡è¦ä¿¡æ¯ï¼Œè¾“å‡ºä¸€å¥è¯æ¦‚æ‹¬ï¼ˆä¸åŒ…å«æ—¶é—´æˆ³ï¼‰ï¼"""

            extraction_response = self.client.chat.completions.create(
                model=JUDGE_MODEL,
                messages=[{"role": "user", "content": extract_prompt}],
                temperature=0.3,
                max_tokens=200
            )
            
            extracted = extraction_response.choices[0].message.content.strip()
            
            # æ¸…ç†å¯èƒ½çš„æ ¼å¼
            extracted = extracted.replace("**", "").replace("- ", "").replace("`", "").strip()
            
            # å¦‚æœæå–åˆ°é‡è¦ä¿¡æ¯ï¼Œä¿å­˜åˆ°é•¿æœŸè®°å¿†
            if extracted and extracted.upper() != "NONE" and len(extracted) > 5:
                print(f"ğŸ“Œ æ£€æµ‹åˆ°é‡è¦ä¿¡æ¯ï¼Œè‡ªåŠ¨ä¿å­˜åˆ°é•¿æœŸè®°å¿†...")
                self.memory.save_memory(extracted, memory_type="long")
        
        except Exception as e:
            print(f"âš ï¸  è‡ªåŠ¨æå–å¤±è´¥: {e}")
    
    def ask(self, question, history=None, tools=None):
        """
        å¤„ç†ç”¨æˆ·é—®é¢˜
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            history: å¯¹è¯å†å² [{"role": "user", "content": "..."}, ...]
            tools: å¯ç”¨å·¥å…·åˆ—è¡¨
        
        Returns:
            str: AIå›ç­”
        """
        if history is None:
            history = []
        if tools is None:
            tools = []
        
        # è·å–å½“å‰æ—¶é—´
        time_info, time_text = get_current_time_info(TIMEZONE)
        
        print(f"\nâ° ç³»ç»Ÿæ—¶é—´ï¼š{time_info['date']} {time_info['weekday']} {time_info['time']}\n")

        # è·å–é•¿æœŸè®°å¿†
        long_term_memory = self.memory.get_long_term_memory()

        # æ„å»ºç³»ç»Ÿæç¤º
        system_prompt = self._build_system_prompt(time_text, long_term_memory)

        # æ„å»ºå®Œæ•´æ¶ˆæ¯åˆ—è¡¨ï¼ˆåŠ å…¥å†å²ï¼‰
        messages = [{"role": "system", "content": system_prompt}]

        # æ·»åŠ å¯¹è¯å†å²
        messages.extend(history)

        # æ·»åŠ å½“å‰é—®é¢˜
        messages.append({"role": "user", "content": question})
        
        print(f"ğŸ¤– é˜¶æ®µ1: ç”¨ {JUDGE_MODEL} åˆ¤æ–­æ˜¯å¦éœ€è¦æœç´¢...\n")
        
        try:
            # ç¬¬ä¸€é˜¶æ®µï¼šç”¨å¿«é€Ÿæ¨¡å‹åˆ¤æ–­æ˜¯å¦éœ€è¦æœç´¢
            response = self.client.chat.completions.create(
                model=JUDGE_MODEL,  # ç”¨å¿«é€Ÿæ¨¡å‹
                messages=messages,
                tools=tools,
                tool_choice="auto"
            )
            
            response_message = response.choices[0].message
            tool_calls = response_message.tool_calls
            
            # å¦‚æœAIå†³å®šä¸æœç´¢ï¼Œç›´æ¥ç”¨å¿«é€Ÿæ¨¡å‹å›ç­”
            if not tool_calls:
                print(f"ğŸ’¡ {JUDGE_MODEL} åˆ¤æ–­ï¼šæ— éœ€æœç´¢")
                print(f"ğŸ¤– ç”¨ {ANSWER_MODEL} å›ç­”...\n")
                
                # ç”¨å¼ºåŠ›æ¨¡å‹é‡æ–°ç”Ÿæˆå›ç­”ï¼ˆå¸¦å†å²ä¸Šä¸‹æ–‡ï¼‰
                final_response = self.client.chat.completions.create(
                    model=ANSWER_MODEL,
                    messages=messages  # åŒ…å«å†å²çš„å®Œæ•´ä¸Šä¸‹æ–‡
                )
                
                answer = final_response.choices[0].message.content
                
            else:
                # AIå†³å®šè¦æœç´¢
                print(f"ğŸ’¡ {JUDGE_MODEL} åˆ¤æ–­ï¼šéœ€è¦æœç´¢ç½‘ç»œ")
                
                # æ˜¾ç¤ºæ‰€æœ‰å·¥å…·è°ƒç”¨
                for tool_call in tool_calls:
                    function_name = tool_call.function.name
                    args = json.loads(tool_call.function.arguments)
                    
                    if function_name == "web_search":
                        print(f"ğŸ“ æœç´¢å…³é”®è¯: {args.get('query')}\n")
                    elif function_name == "memory_search":
                        print(f"ğŸ§  æœç´¢è®°å¿†: {args.get('query')}\n")
                    elif function_name == "memory_save":
                        print(f"ğŸ’¾ ä¿å­˜è®°å¿†: {args.get('text')[:50]}...\n")

                # æ‰§è¡Œå·¥å…·è°ƒç”¨
                messages.append(response_message)

                for tool_call in tool_calls:
                    function_name = tool_call.function.name
                    function_args = json.loads(tool_call.function.arguments)
                    
                    # å¤„ç†ç½‘ç»œæœç´¢
                    if function_name == "web_search":
                        search_result = web_search(
                            function_args.get("query"), 
                            self.searxng_url, 
                            self.max_fetch
                        )
                        
                        if search_result["success"]:
                            formatted_result = "æœç´¢ç»“æœï¼š\n\n"
                            for i, r in enumerate(search_result["results"], 1):
                                formatted_result += f"ã€ç»“æœ{i}ã€‘\n"
                                formatted_result += f"æ ‡é¢˜ï¼š{r['title']}\n"
                                formatted_result += f"é“¾æ¥ï¼š{r['url']}\n"
                                formatted_result += f"æ‘˜è¦ï¼š{r['snippet']}\n"
                                if r['content']:
                                    formatted_result += f"æ­£æ–‡å†…å®¹ï¼š\n{r['content']}\n"
                                formatted_result += "\n" + "="*60 + "\n\n"
                        else:
                            formatted_result = f"æœç´¢å¤±è´¥ï¼š{search_result.get('message', search_result.get('error'))}"
                        
                        messages.append({
                            "tool_call_id": tool_call.id,
                            "role": "tool",
                            "name": function_name,
                            "content": formatted_result
                        })
                    
                    # å¤„ç†è®°å¿†æœç´¢
                    elif function_name == "memory_search":
                        query = function_args.get("query")
                        top_k = function_args.get("top_k", 5)
                        
                        results = self.memory.search_memory(query, top_k=top_k)
                        
                        if results:
                            formatted_result = f"æ‰¾åˆ° {len(results)} æ¡ç›¸å…³è®°å¿†ï¼š\n\n"
                            for i, r in enumerate(results, 1):
                                formatted_result += f"ã€è®°å¿†{i}ã€‘(ç›¸å…³åº¦: {r['score']:.2f})\n"
                                formatted_result += f"å†…å®¹ï¼š{r['text']}\n"
                                formatted_result += f"æ¥æºï¼š{r['path']}\n\n"
                        else:
                            formatted_result = "æœªæ‰¾åˆ°ç›¸å…³è®°å¿†"
                        
                        messages.append({
                            "tool_call_id": tool_call.id,
                            "role": "tool",
                            "name": function_name,
                            "content": formatted_result
                        })
                    
                    # å¤„ç†è®°å¿†ä¿å­˜
                    elif function_name == "memory_save":
                        text = function_args.get("text")
                        memory_type = function_args.get("memory_type", "short")
                        
                        self.memory.save_memory(text, memory_type=memory_type)
                        
                        messages.append({
                            "tool_call_id": tool_call.id,
                            "role": "tool",
                            "name": function_name,
                            "content": "âœ… è®°å¿†å·²ä¿å­˜"
                        })
                
                # ç¬¬äºŒé˜¶æ®µï¼šç”¨å¼ºåŠ›æ¨¡å‹æ•´åˆæœç´¢ç»“æœå¹¶å›ç­”
                print(f"ğŸ¤– é˜¶æ®µ2: ç”¨ {ANSWER_MODEL} æ•´åˆç»“æœå¹¶å›ç­”...\n")
                
                final_response = self.client.chat.completions.create(
                    model=ANSWER_MODEL,  # ç”¨å¼ºåŠ›æ¨¡å‹
                    messages=messages
                )
                
                answer = final_response.choices[0].message.content
            
            # è‡ªåŠ¨æå–é‡è¦ä¿¡æ¯
            self._extract_important_info(question, answer)
            
            # ä¿å­˜çŸ­æœŸè®°å¿†ï¼ˆå®Œæ•´å¯¹è¯ï¼‰
            conversation_log = f"""---
            ## [{time_info['time']}] å¯¹è¯è®°å½•

            **ç”¨æˆ·é—®**ï¼š{question}

            **AIç­”**ï¼š{answer}
            """

            self.memory.save_memory(conversation_log, memory_type="short")
            
            return answer
            
        except Exception as e:
            return f"âŒ AIè°ƒç”¨å¤±è´¥: {e}"
    
    def update_history(self, question, answer, max_history=10):
        """æ›´æ–°å¯¹è¯å†å²
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            answer: AIå›ç­”
            max_history: æœ€å¤§å†å²è®°å½•æ•°
        """
        self.conversation_history.append({"role": "user", "content": question})
        self.conversation_history.append({"role": "assistant", "content": answer})
        
        if len(self.conversation_history) > max_history * 2:
            self.conversation_history = self.conversation_history[-(max_history * 2):]
    
    def clear_history(self):
        """æ¸…ç©ºå¯¹è¯å†å²"""
        self.conversation_history.clear()
    
    def get_history(self):
        """è·å–å¯¹è¯å†å²"""
        return self.conversation_history.copy()